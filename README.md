---
title: Multimodal RAG System
emoji: ğŸ¢
colorFrom: blue
colorTo: pink
sdk: docker
pinned: false
---

# ğŸ¤– Multimodal RAG System

A powerful **Retrieval-Augmented Generation (RAG)** system built with **FastAPI**, **Streamlit**, and **LangChain**. This application allows users to upload various document types (PDF, DOCX, TXT, CSV, MD, ZIP), ingest them into a vector database, and ask complex questions using **Llama-3.3-70B** (via Groq) and **Hugging Face** embeddings.

![Python](https://img.shields.io/badge/Python-3.8%2B-blue)
![FastAPI](https://img.shields.io/badge/FastAPI-0.68%2B-009688)
![Streamlit](https://img.shields.io/badge/Streamlit-1.0%2B-FF4B4B)
![LangChain](https://img.shields.io/badge/LangChain-ğŸ¦œï¸ğŸ”—-green)

## âœ¨ Features

- **ğŸ“‚ Multi-Format Ingestion**: Supports PDF, DOCX, TXT, CSV, Markdown, and Images.
- **ğŸ“¦ ZIP Archive Support**: Automatically extracts and processes files from uploaded ZIPs.
- **ğŸ” Vector Search**: Uses **FAISS** for efficient similarity search and retrieval.
- **ğŸ§  Advanced LLM**: Powered by **Llama-3.3-70B** via Groq for high-quality answers.
- **ğŸ’¬ Interactive Chat UI**: Clean, responsive Streamlit interface with chat history.
- **ğŸš€ FASTApi Backend**: Robust backend for handling ingestion and query processing.

## ğŸ› ï¸ Tech Stack

- **Backend**: FastAPI, Uvicorn
- **Frontend**: Streamlit
- **Orchestration**: LangChain
- **Vector DB**: FAISS (Facebook AI Similarity Search)
- **Embeddings**: HuggingFace (`sentence-transformers`)
- **LLM**: Groq API (Llama-3.3-70B)
- **PDF Processing**: PyMuPDF, pdfplumber

## ğŸš€ Getting Started

### Prerequisites

- Python 3.8 or higher
- [Groq API Key](https://console.groq.com/)
- [Hugging Face Token](https://huggingface.co/settings/tokens)

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/yourusername/multimodal-rag-system.git
   cd multimodal-rag-system
   ```

2. **Create a virtual environment**
   ```bash
   python -m venv venv
   # Windows
   .\venv\Scripts\activate
   # Mac/Linux
   source venv/bin/activate
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Environment Configuration**
   Create a `.env` file in the root directory (copy from `.env.example` if available):
   ```bash
   cp .exampleenv .env
   ```
   Add your API keys:
   ```ini
   HF_TOKEN=your_huggingface_token
   GROQ_API_KEY=your_groq_api_key
   ```

## ğŸƒâ€â™‚ï¸ Usage

### 1. Start the Backend API
Run the FastAPI server to handle ingestion and retrieval logic.
```bash
uvicorn app:app --reload
```
*Server will start at `http://127.0.0.1:8000`*

### 2. Launch the User Interface
Open a new terminal and run the Streamlit app.
```bash
streamlit run ui.py
```
*The UI will open in your browser at `http://localhost:8501`*

## ğŸ“ Project Structure

```
multimodal-rag-system/
â”œâ”€â”€ app.py                 # FastAPI backend entry point
â”œâ”€â”€ ui.py                  # Streamlit frontend application
â”œâ”€â”€ src/                   # Source code modules
â”‚   â”œâ”€â”€ ingest.py          # File loading and processing logic
â”‚   â”œâ”€â”€ vector_store.py    # FAISS vector database management
â”‚   â”œâ”€â”€ rag.py             # RAG pipeline and LLM interaction
â”‚   â”œâ”€â”€ config.py          # Configuration settings
â”‚   â””â”€â”€ logger.py          # Logging setup
â”œâ”€â”€ requirements.txt       # Project dependencies
â”œâ”€â”€ .env                   # Environment variables (do not commit)
â””â”€â”€ README.md              # Project documentation
```

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.
